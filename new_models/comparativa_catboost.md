# Comparativa Detallada: CatBoost para Predicci√≥n de Ventas

Este documento proporciona un an√°lisis exhaustivo de dos implementaciones de modelos CatBoost para la predicci√≥n de series temporales de ventas: **catBoost.ipynb** y **catBoostRegressor.ipynb**.

---

## üìã √çndice

1. [Resumen Ejecutivo](#1-resumen-ejecutivo)
2. [catBoost.ipynb - An√°lisis Detallado](#2-catboostipynb---an√°lisis-detallado)
3. [catBoostRegressor.ipynb - An√°lisis Detallado](#3-catboostregressoripynb---an√°lisis-detallado)
4. [Comparaci√≥n Detallada](#4-comparaci√≥n-detallada)
5. [M√©tricas y Resultados](#5-m√©tricas-y-resultados)
6. [Conclusiones y Recomendaciones](#6-conclusiones-y-recomendaciones)

---

## 1. Resumen Ejecutivo

| Caracter√≠stica | catBoost.ipynb | catBoostRegressor.ipynb |
|----------------|----------------|------------------------|
| **Enfoque** | Panel de datos completo | Datos disponibles √∫nicamente |
| **Features categ√≥ricas** | `series_id` | `brand`, `supermarket`, `variant`, `pack_size` |
| **Funci√≥n de p√©rdida** | RMSE | MAE |
| **Iteraciones** | 5,000 | 500 (con early stopping) |
| **Learning rate** | 0.03 | 0.1 |
| **Profundidad** | 8 | 6 |
| **Predicci√≥n futura** | No | S√≠ (m√©todo recursivo) |
| **MAE en test** | 11,203.80 | 8,686.28 |
| **R¬≤** | 0.7058 | N/A |

---

## 2. catBoost.ipynb - An√°lisis Detallado

### 2.1 Carga y Preparaci√≥n de Datos

El notebook comienza importando los datos desde `Datos_Market_copy.xlsx` y utilizando una clase utilitaria `SalesAnalysis` para el preprocesamiento inicial.

```python
raw_data = pd.read_excel("../data/Datos_Market_copy.xlsx")
sa = SalesAnalysis(raw_data)
data = sa.data
```

**Filtrado de datos:**
- Se filtran √∫nicamente las 3 marcas principales: `brand-35`, `brand-14`, `brand-15`
- Total de datos tras filtrado: **3,403 filas**

**Creaci√≥n del identificador de serie:**
```python
data['series_id'] = (
    data['brand'].astype(str) + '_' + 
    data['supermarket'].astype(str) + '_' + 
    data['variant'].astype(str) + '_' + 
    data['pack.size'].astype(str)
)
```

Esta combinaci√≥n genera un identificador √∫nico para cada combinaci√≥n de marca, supermercado, variante y tama√±o de empaque.

### 2.2 An√°lisis de Completitud de Series

El notebook implementa una funci√≥n para detectar series con datos incompletos:

```python
def series_less_than_36(data: pd.DataFrame, months: int = 36) -> pd.DataFrame:
    # Identifica series con menos de 36 meses de datos
```

**Resultados del an√°lisis:**
- **67 series** (59.29%) tienen datos completos (‚â•36 meses)
- **46 series** (40.71%) tienen datos incompletos (<36 meses)

### 2.3 Construcci√≥n del Panel Completo (Punto Diferenciador Clave)

**Este es el aspecto m√°s distintivo de este notebook.** Se crea un calendario completo para evitar discontinuidades temporales:

```python
all_months = pd.date_range(data["date"].min(), data["date"].max(), freq="ME")
uniques = pd.DataFrame({"series_id": data["series_id"].unique()})
all_months_df = pd.DataFrame({"date": all_months})
full = uniques.assign(_key=1).merge(all_months_df.assign(_key=1), on="_key").drop("_key", axis=1)
full = full.merge(data, on=["series_id", "date"], how="left")
```

Este proceso:
1. Genera todas las fechas posibles (rango completo)
2. Crea un producto cartesiano entre series y fechas
3. Hace un left join con los datos reales
4. **Resultado: 100% de las series tienen 36 datos** (incluyendo NaN donde no hab√≠a datos originales)

### 2.4 Tratamiento de Valores Faltantes

```python
# Crear flag de datos faltantes
full["missing"] = full["volume.sales"].isna().astype(int)

# Rellenar ventas faltantes con 0
full["volume.sales"] = full["volume.sales"].fillna(0.0)

# Rellenar precios faltantes con forward fill y mediana
full["price"] = full.groupby("series_id")["price"].ffill()
full["price"] = full["price"].fillna(full["price"].median())
```

**Estrategia de imputaci√≥n:**
- `missing`: Variable binaria (1/0) que indica si el dato era originalmente faltante
- `volume.sales`: Se imputan con 0 los meses sin ventas
- `price`: Se usa forward fill por serie, y mediana global como fallback

### 2.5 Transformaci√≥n de la Variable Objetivo

```python
full["y"] = np.log1p(full["volume.sales"])
```

Se aplica transformaci√≥n logar√≠tmica `log(1+x)` para:
- Reducir asimetr√≠a de la distribuci√≥n
- Estabilizar la varianza
- Manejar valores cero (gracias a +1)

### 2.6 Ingenier√≠a de Features

#### Features de Calendario
```python
full["year"] = full["date"].dt.year
full["month"] = full["date"].dt.month
full["quarter"] = full["date"].dt.quarter

# Codificaci√≥n c√≠clica para capturar estacionalidad
full["month_sin"] = np.sin(2*np.pi*full["month"]/12)
full["month_cos"] = np.cos(2*np.pi*full["month"]/12)
```

La codificaci√≥n seno/coseno es importante porque:
- Captura la naturaleza c√≠clica del mes (diciembre est√° "cerca" de enero)
- Proporciona una representaci√≥n continua de la estacionalidad

#### Lags (Retardos)
```python
def add_lags(panel, col, lags=(1,2,3,6,12)):
    for l in lags:
        panel[f"{col}_lag_{l}"] = panel.groupby("series_id")[col].shift(l)
    return panel

full = add_lags(full, "y")           # Lags 1,2,3,6,12 de la variable objetivo
full = add_lags(full, "price", lags=(1,))  # Lag 1 del precio
```

#### Medias M√≥viles (Rolling Means)
```python
# Shift(1) CR√çTICO para evitar data leakage
full["y_roll_mean_3"] = full.groupby("series_id")["y"].shift(1).rolling(3, min_periods=1).mean()
full["y_roll_mean_6"] = full.groupby("series_id")["y"].shift(1).rolling(6, min_periods=1).mean()
full["y_roll_mean_12"] = full.groupby("series_id")["y"].shift(1).rolling(12, min_periods=1).mean()
```

**Nota importante:** Se usa `shift(1)` antes del rolling para evitar **data leakage** (filtraci√≥n de informaci√≥n del futuro).

#### Cambio de Precio
```python
full["price_change"] = full["price"] - full["price_lag_1"]
```

### 2.7 Definici√≥n del Modelo

**Features utilizadas:**
```python
feature_cols = (
    ["series_id"]  # Categ√≥rica
    + ["price", "missing", "year", "month", "quarter", "month_sin", "month_cos"]
    + [c for c in full.columns if c.startswith("y_lag_") or c.startswith("price_lag_")]
    + ["y_roll_mean_3", "y_roll_mean_6", "y_roll_mean_12", "price_change"]
)

cat_features = ["series_id"]  # Solo series_id como categ√≥rica
```

**Configuraci√≥n del modelo:**
```python
model = CatBoostRegressor(
    loss_function="RMSE",
    iterations=5000,
    learning_rate=0.03,
    depth=8,
    random_seed=42,
    eval_metric="RMSE",
    verbose=200
)
```

| Hiperpar√°metro | Valor | Justificaci√≥n |
|----------------|-------|---------------|
| `loss_function` | RMSE | Penaliza m√°s los errores grandes |
| `iterations` | 5,000 | Modelo con muchas iteraciones |
| `learning_rate` | 0.03 | Tasa conservadora para mejor generalizaci√≥n |
| `depth` | 8 | √Årboles profundos para capturar patrones complejos |

### 2.8 Split Temporal

```python
cutoff = pd.Timestamp("2023-06-30")
train_idx = full["date"] <= cutoff
valid_idx = full["date"] > cutoff
```

- **Train:** Desde inicio hasta 30/06/2023 (2,814 filas)
- **Test:** Desde 01/07/2023 hasta 31/12/2023 (589 filas)

### 2.9 Uso de Pool de CatBoost

```python
train_pool = Pool(X_train, y_train, cat_features=cat_features)
valid_pool = Pool(X_valid, y_valid, cat_features=cat_features)
```

Los `Pool` de CatBoost permiten:
- Manejo eficiente de memoria
- Procesamiento optimizado de features categ√≥ricas
- Mejor performance en entrenamiento

### 2.10 Evaluaci√≥n y Visualizaci√≥n

**M√©tricas obtenidas:**
- **MAE:** 11,203.80
- **RMSE:** 28,190.91
- **R¬≤:** 0.7058

El notebook incluye visualizaciones extensas:
1. Gr√°fico agregado: Predicciones vs reales por fecha
2. Scatter plot con l√≠nea perfecta
3. Distribuci√≥n de errores (histograma y boxplot)
4. Series individuales representativas
5. Resumen de m√©tricas por serie

---

## 3. catBoostRegressor.ipynb - An√°lisis Detallado

### 3.1 Carga de Datos

Similar al primer notebook, pero **incluye la marca "other"** en los datos cargados (143 series vs 113):

```python
data = data[
    data["brand"].isin(["brand-35", "brand-14", "brand-15"])
]  # Aunque el output muestra 143 combinaciones que incluyen 'other'
```

**Datos cargados:** 4,306 filas (m√°s que catBoost.ipynb)

### 3.2 Creaci√≥n de Features (Sin Panel Completo)

**Diferencia fundamental:** Este notebook NO crea un calendario completo. Trabaja √∫nicamente con los datos disponibles.

#### Features Temporales
```python
data['month'] = data['date'].dt.month
data['year'] = data['date'].dt.year
```

**Nota:** No utiliza codificaci√≥n c√≠clica (sin/cos) ni quarter.

#### Lags
```python
data['lag_1'] = data.groupby('series_id')['volume.sales'].shift(1)
data['lag_2'] = data.groupby('series_id')['volume.sales'].shift(2)
data['lag_3'] = data.groupby('series_id')['volume.sales'].shift(3)
data['lag_12'] = data.groupby('series_id')['volume.sales'].shift(12)

data['price_lag_1'] = data.groupby('series_id')['price'].shift(1)
data['price_lag_12'] = data.groupby('series_id')['price'].shift(12)
```

**Diferencias con catBoost.ipynb:**
- No incluye `lag_6` de la variable objetivo
- Incluye `price_lag_12` (estacionalidad del precio)

#### Rolling Means
```python
data['volume_sales_shifted'] = data.groupby('series_id')['volume.sales'].shift(1)
data['rolling_mean_3'] = data.groupby('series_id')['volume_sales_shifted'].rolling(window=3, min_periods=1).mean()
data['rolling_mean_6'] = data.groupby('series_id')['volume_sales_shifted'].rolling(window=6, min_periods=1).mean()
```

**Diferencia:** No incluye `rolling_mean_12`.

### 3.3 Transformaci√≥n del Target

```python
data['target_log'] = np.log1p(data['volume.sales'])
```

Misma transformaci√≥n que catBoost.ipynb.

### 3.4 Definici√≥n de Features

```python
feature_cols = [
    'month', 'year',
    'lag_1', 'lag_2', 'lag_3', 'lag_12',
    'rolling_mean_3', 'rolling_mean_6',
    'price', 'price_lag_1', 'price_lag_12',
    'brand', 'supermarket', 'variant', 'pack_size'
]

categorical_features = ['brand', 'supermarket', 'variant', 'pack_size']
```

**Diferencia cr√≠tica:** 
- **NO usa `series_id` como feature categ√≥rica**
- **USA las componentes individuales**: brand, supermarket, variant, pack_size
- **15 features** vs m√°s features en catBoost.ipynb

### 3.5 Split Temporal

```python
train_cutoff = pd.Timestamp('2023-06-30')
test_start = pd.Timestamp('2023-07-01')
test_end = pd.Timestamp('2023-12-31')

train_data = data[data['date'] <= train_cutoff].copy()
test_data = data[(data['date'] >= test_start) & (data['date'] <= test_end)].copy()
```

- **Train:** 3,579 filas
- **Test:** 727 filas

### 3.6 Manejo de NaN (Diferente Estrategia)

```python
# Eliminar filas donde lag_12 es NaN
train_data_clean = train_data.dropna(subset=['lag_12']).copy()
test_data_clean = test_data.dropna(subset=['lag_12']).copy()
```

**Estrategia:** En lugar de imputar, **elimina las filas** donde faltan valores de lag_12.

**Consecuencia:**
- Train: 3,579 ‚Üí **1,968 filas** (p√©rdida de 1,611 filas = 45%)
- Test: 727 ‚Üí **672 filas** (p√©rdida de 55 filas = 7.5%)

### 3.7 Configuraci√≥n del Modelo

```python
model = CatBoostRegressor(
    loss_function='MAE',        # ‚Üê Diferente: MAE vs RMSE
    iterations=500,             # ‚Üê Diferente: 500 vs 5000
    learning_rate=0.1,          # ‚Üê Diferente: 0.1 vs 0.03
    depth=6,                    # ‚Üê Diferente: 6 vs 8
    random_seed=42,
    verbose=100,
    cat_features=cat_indices
)

model.fit(
    X_train, y_train,
    eval_set=(X_test, y_test),
    early_stopping_rounds=50,   # ‚Üê Nuevo: early stopping
    verbose=100
)
```

| Hiperpar√°metro | Valor | Comparaci√≥n |
|----------------|-------|-------------|
| `loss_function` | MAE | M√°s robusto a outliers |
| `iterations` | 500 | Entrenamiento m√°s r√°pido |
| `learning_rate` | 0.1 | Tasa m√°s agresiva |
| `depth` | 6 | √Årboles menos profundos |
| `early_stopping` | 50 | Previene sobreajuste |

**Resultado del entrenamiento:**
- El modelo se detuvo en la iteraci√≥n **166** por early stopping
- Mejor test RMSE en iteraci√≥n 166

### 3.8 M√©tricas de Evaluaci√≥n

```python
def smape(y_true, y_pred):
    """Symmetric Mean Absolute Percentage Error"""
    numerator = np.abs(y_true - y_pred)
    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2
    return np.mean(numerator / (denominator + 1e-9)) * 100

def wape(y_true, y_pred):
    """Weighted Absolute Percentage Error"""
    numerator = np.sum(np.abs(y_true - y_pred))
    denominator = np.sum(np.abs(y_true))
    return (numerator / (denominator + 1e-9)) * 100
```

**M√©tricas obtenidas:**
- **MAE:** 8,686.28
- **sMAPE:** 36.58%
- **WAPE:** 25.69%

### 3.9 Predicciones Futuras (Feature Exclusiva)

Este notebook incluye una **funci√≥n de predicci√≥n recursiva** para generar forecasts futuros:

```python
def generate_future_predictions(model, last_data, horizon=6, price_scenario='same'):
    """
    Genera predicciones futuras usando m√©todo recursivo.
    
    Parameters:
    -----------
    model: CatBoostRegressor entrenado
    last_data: DataFrame con los √∫ltimos datos conocidos
    horizon: n√∫mero de meses a predecir
    price_scenario: 'same', 'plus3', 'minus3'
    """
```

**Caracter√≠sticas del m√©todo recursivo:**
1. Usa predicciones anteriores como inputs para predicciones siguientes
2. Actualiza lags din√°micamente: `lag_1 = predicci√≥n_t-1`, `lag_2 = lag_1_anterior`, etc.
3. Actualiza rolling means con nuevas predicciones
4. Mantiene lag_12 est√°tico (estacionalidad hist√≥rica)

**Escenarios de precio:**
- `same`: Mantiene el √∫ltimo precio conocido
- `plus3`: Incremento del 3% sobre precio base
- `minus3`: Decremento del 3% sobre precio base

**Predicciones generadas:** 774 predicciones por escenario (129 series √ó 6 meses)

### 3.10 Exportaci√≥n de Resultados

```python
# M√©tricas por serie
metrics_df.to_csv('catboost_metrics_by_series.csv', index=False)

# Predicciones futuras
forecast_same.to_csv('catboost_forecast_same_price.csv', index=False)
forecast_plus3.to_csv('catboost_forecast_plus3_price.csv', index=False)
forecast_minus3.to_csv('catboost_forecast_minus3_price.csv', index=False)

# Predicciones del test set
test_predictions.to_csv('catboost_test_predictions.csv', index=False)
```

---

## 4. Comparaci√≥n Detallada

### 4.1 Estrategia de Datos

| Aspecto | catBoost.ipynb | catBoostRegressor.ipynb |
|---------|----------------|------------------------|
| **Manejo de series incompletas** | Crea panel completo + imputa | Elimina filas con NaN |
| **Flag de datos faltantes** | S√≠ (`missing`) | No |
| **Datos de entrenamiento** | 2,814 filas | 1,968 filas |
| **Datos de test** | 589 filas | 672 filas |
| **Series evaluadas** | 113 | 122 |

**Ventajas de cada enfoque:**

**catBoost.ipynb (Panel completo):**
- ‚úÖ No pierde informaci√≥n temporal
- ‚úÖ Permite al modelo aprender patrones de "meses sin ventas"
- ‚úÖ El flag `missing` puede ser predictivo
- ‚ùå Introduce datos artificiales (imputados)

**catBoostRegressor.ipynb (Eliminaci√≥n):**
- ‚úÖ Trabaja solo con datos reales
- ‚úÖ M√°s simple de implementar
- ‚ùå Pierde ~45% de datos de entrenamiento
- ‚ùå Puede perder patrones importantes

### 4.2 Ingenier√≠a de Features

| Feature | catBoost.ipynb | catBoostRegressor.ipynb |
|---------|----------------|------------------------|
| **month** | ‚úÖ + sin/cos | ‚úÖ (solo num√©rico) |
| **year** | ‚úÖ | ‚úÖ |
| **quarter** | ‚úÖ | ‚ùå |
| **lag_1, lag_2, lag_3** | ‚úÖ | ‚úÖ |
| **lag_6** | ‚úÖ | ‚ùå |
| **lag_12** | ‚úÖ | ‚úÖ |
| **rolling_mean_3, _6** | ‚úÖ | ‚úÖ |
| **rolling_mean_12** | ‚úÖ | ‚ùå |
| **price_lag_1** | ‚úÖ | ‚úÖ |
| **price_lag_12** | ‚ùå | ‚úÖ |
| **price_change** | ‚úÖ | ‚ùå |
| **missing flag** | ‚úÖ | ‚ùå |

### 4.3 Features Categ√≥ricas

| Notebook | Features Categ√≥ricas | Implicaci√≥n |
|----------|---------------------|-------------|
| **catBoost.ipynb** | `series_id` | Aprende patrones espec√≠ficos por serie |
| **catBoostRegressor.ipynb** | `brand`, `supermarket`, `variant`, `pack_size` | Aprende patrones generalizables por componentes |

**An√°lisis:**
- `series_id`: Permite embeddings espec√≠ficos por serie, pero puede sobreajustar con pocas observaciones por serie
- Componentes separados: Mayor generalizaci√≥n, puede transferir conocimiento entre series similares

### 4.4 Hiperpar√°metros

| Par√°metro | catBoost.ipynb | catBoostRegressor.ipynb | Impacto |
|-----------|----------------|------------------------|---------|
| `loss_function` | RMSE | MAE | MAE es m√°s robusto a outliers |
| `iterations` | 5,000 | 500 | Mayor capacidad vs. riesgo de sobreajuste |
| `learning_rate` | 0.03 | 0.1 | Convergencia lenta/estable vs. r√°pida/riesgosa |
| `depth` | 8 | 6 | Mayor complejidad vs. mejor generalizaci√≥n |
| `early_stopping` | No | 50 rounds | Previene sobreajuste |

### 4.5 Funcionalidad Adicional

| Funcionalidad | catBoost.ipynb | catBoostRegressor.ipynb |
|---------------|----------------|------------------------|
| Predicci√≥n en test set | ‚úÖ | ‚úÖ |
| Predicci√≥n futura recursiva | ‚ùå | ‚úÖ |
| Escenarios de precio | ‚ùå | ‚úÖ (same, +3%, -3%) |
| Visualizaciones | ‚úÖ Extensas | ‚úÖ Moderadas |
| Exportaci√≥n a CSV | ‚ùå | ‚úÖ |
| M√©tricas por serie | ‚úÖ | ‚úÖ |
| R¬≤ Score | ‚úÖ | ‚ùå |
| sMAPE/WAPE | ‚ùå | ‚úÖ |

---

## 5. M√©tricas y Resultados

### 5.1 Comparaci√≥n de Performance

| M√©trica | catBoost.ipynb | catBoostRegressor.ipynb | Mejor |
|---------|----------------|------------------------|-------|
| **MAE** | 11,203.80 | 8,686.28 | catBoostRegressor ‚úÖ |
| **RMSE** | 28,190.91 | N/A | - |
| **R¬≤** | 0.7058 | N/A | - |
| **sMAPE** | N/A | 36.58% | - |
| **WAPE** | N/A | 25.69% | - |

### 5.2 An√°lisis de la Diferencia en MAE

La diferencia de ~2,500 en MAE podr√≠a explicarse por:

1. **Funci√≥n de p√©rdida:** MAE optimiza directamente para el error absoluto medio
2. **Early stopping:** Previene sobreajuste en catBoostRegressor
3. **Datos de evaluaci√≥n diferentes:** Distintas filas en test set
4. **Features categ√≥ricas:** El uso de componentes individuales puede generalizar mejor

### 5.3 Series con Mayor/Menor Error

**catBoost.ipynb - Peor desempe√±o:**
- `brand-35_supermarket-D_standard_351 - 500 GR`: MAE = 129,338
- `brand-35_supermarket-A_standard_351 - 500 GR`: MAE = 122,714

**catBoostRegressor.ipynb - Peor desempe√±o:**
- `brand-35_supermarket-D_standard_351 - 500 GR`: MAE = 77,119
- `brand-35_supermarket-A_standard_351 - 500 GR`: MAE = 84,779

Las mismas series problem√°ticas aparecen en ambos notebooks, lo que sugiere que son inherentemente dif√≠ciles de predecir (posiblemente por alta variabilidad o patrones inusuales).

---

## 6. Conclusiones y Recomendaciones

### 6.1 Conclusiones

1. **catBoostRegressor.ipynb obtiene mejor MAE** (8,686 vs 11,204), probablemente por:
   - Optimizaci√≥n directa de MAE
   - Early stopping que previene sobreajuste
   - Mejor generalizaci√≥n con features categ√≥ricas descompuestas

2. **catBoost.ipynb es m√°s completo** en t√©rminos de:
   - Manejo de datos faltantes (no pierde informaci√≥n)
   - Features de calendario m√°s sofisticadas (sin/cos)
   - Visualizaciones m√°s extensas

3. **catBoostRegressor.ipynb es m√°s pr√°ctico** para producci√≥n:
   - Genera predicciones futuras
   - Incluye an√°lisis de sensibilidad a precios
   - Exporta resultados a CSV

### 6.2 Recomendaciones

**Para mejorar catBoost.ipynb:**
- Implementar early stopping
- Considerar cambiar a MAE como funci√≥n de p√©rdida
- A√±adir predicci√≥n recursiva futura
- Exportar resultados a CSV

**Para mejorar catBoostRegressor.ipynb:**
- Implementar el enfoque de panel completo en lugar de eliminar NaN
- A√±adir codificaci√≥n c√≠clica (sin/cos) para el mes
- Incluir `lag_6` y `rolling_mean_12`
- A√±adir el flag `missing` como feature

**Enfoque h√≠brido recomendado:**
```python
# Combinar lo mejor de ambos notebooks:
# 1. Panel completo + flag missing (de catBoost.ipynb)
# 2. Features categ√≥ricas descompuestas (de catBoostRegressor.ipynb)
# 3. MAE + early stopping (de catBoostRegressor.ipynb)
# 4. Sin/cos encoding + m√°s features (de catBoost.ipynb)
# 5. Predicci√≥n recursiva futura (de catBoostRegressor.ipynb)
```

### 6.3 Tabla Resumen Final

| Criterio | Ganador | Raz√≥n |
|----------|---------|-------|
| **Precisi√≥n (MAE)** | catBoostRegressor | 8,686 vs 11,204 |
| **Manejo de datos** | catBoost | No pierde informaci√≥n |
| **Features engineering** | catBoost | M√°s sofisticado |
| **Producci√≥n/Uso real** | catBoostRegressor | Predicciones futuras + CSV |
| **Interpretabilidad** | catBoostRegressor | Features individuales |
| **Prevenci√≥n sobreajuste** | catBoostRegressor | Early stopping |

---

## Anexo: Estructura de Features

### catBoost.ipynb
```
Features (total: ~18):
‚îú‚îÄ‚îÄ Categ√≥ricas
‚îÇ   ‚îî‚îÄ‚îÄ series_id
‚îú‚îÄ‚îÄ Temporales
‚îÇ   ‚îú‚îÄ‚îÄ year, month, quarter
‚îÇ   ‚îî‚îÄ‚îÄ month_sin, month_cos
‚îú‚îÄ‚îÄ Lags de ventas
‚îÇ   ‚îî‚îÄ‚îÄ y_lag_1, y_lag_2, y_lag_3, y_lag_6, y_lag_12
‚îú‚îÄ‚îÄ Lags de precio
‚îÇ   ‚îî‚îÄ‚îÄ price_lag_1
‚îú‚îÄ‚îÄ Rolling means
‚îÇ   ‚îî‚îÄ‚îÄ y_roll_mean_3, y_roll_mean_6, y_roll_mean_12
‚îú‚îÄ‚îÄ Precio
‚îÇ   ‚îî‚îÄ‚îÄ price, price_change
‚îî‚îÄ‚îÄ Indicador
    ‚îî‚îÄ‚îÄ missing
```

### catBoostRegressor.ipynb
```
Features (total: 15):
‚îú‚îÄ‚îÄ Categ√≥ricas
‚îÇ   ‚îî‚îÄ‚îÄ brand, supermarket, variant, pack_size
‚îú‚îÄ‚îÄ Temporales
‚îÇ   ‚îî‚îÄ‚îÄ month, year
‚îú‚îÄ‚îÄ Lags de ventas
‚îÇ   ‚îî‚îÄ‚îÄ lag_1, lag_2, lag_3, lag_12
‚îú‚îÄ‚îÄ Lags de precio
‚îÇ   ‚îî‚îÄ‚îÄ price_lag_1, price_lag_12
‚îú‚îÄ‚îÄ Rolling means
‚îÇ   ‚îî‚îÄ‚îÄ rolling_mean_3, rolling_mean_6
‚îî‚îÄ‚îÄ Precio
    ‚îî‚îÄ‚îÄ price
```

---

*Documento generado para el an√°lisis comparativo de modelos CatBoost en el proyecto TFG_ADE*
