{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a74b3b0a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/oscarjimenezbou/Documents/TFG_ADE/code/TFG/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "from utilities import *\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "raw_data = pd.read_excel(\"../data/Datos_Market_copy.xlsx\")\n",
        "\n",
        "sa = SalesAnalysis(raw_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2a08dbec",
      "metadata": {},
      "outputs": [],
      "source": [
        "%run 1_preprocessing_data.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7eb3552a",
      "metadata": {},
      "outputs": [],
      "source": [
        "(\n",
        "    data,\n",
        "    filter_data, \n",
        "    train_data,\n",
        "    test_data,\n",
        "    y_train_boxcox,\n",
        "    y_test_boxcox,\n",
        "    boxcox_transformation_info,\n",
        ") = run_preprocessing(ARIMA_model=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "410a6e53",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "date            datetime64[ns]\n",
            "volume.sales           float64\n",
            "unit.sales               int64\n",
            "value.sales            float64\n",
            "supermarket             object\n",
            "variant                 object\n",
            "pack.size               object\n",
            "brand                   object\n",
            "price                  float64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(train_data.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88a6398c",
      "metadata": {},
      "source": [
        "ARIMAX\n",
        "\n",
        "Realizamos un modelo ARIMA + ex√≥genas global"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fb6002e",
      "metadata": {},
      "source": [
        "1. Modelo de regresi√≥n para sacar las variables ex√≥genas junto a sus coeficientes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bfb444cc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F√≥rmula del modelo:\n",
            "volume_sales ~ price + C(supermarket) + C(variant) + C(pack_size) + C(brand) + (price + C(brand)) ** 2\n",
            "Iteraci√≥n 1: Eliminando 'C(pack_size)[T.450 - 600GR]' (p-valor = 0.8764)\n",
            "Iteraci√≥n 2: Eliminando 'price' (p-valor = 0.5457)\n",
            "Iteraci√≥n 3: Eliminando 'C(supermarket)[T.supermarket-C]' (p-valor = 0.0649)\n",
            "Iteraci√≥n 4: Eliminando 'price:C(brand)[T.brand-15]' (p-valor = 0.0688)\n",
            "Iteraci√≥n 5: Todas las variables restantes son significativas (p-valor ‚â§ 0.05)\n",
            "\n",
            "Resumen:\n",
            "  Variables iniciales: 18\n",
            "  Variables seleccionadas: 14\n",
            "  Variables eliminadas: 4\n",
            "  R¬≤ ajustado: 0.3850\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:           volume_sales   R-squared:                       0.387\n",
            "Model:                            OLS   Adj. R-squared:                  0.385\n",
            "Method:                 Least Squares   F-statistic:                     167.6\n",
            "Date:                Tue, 27 Jan 2026   Prob (F-statistic):               0.00\n",
            "Time:                        19:10:49   Log-Likelihood:                -41636.\n",
            "No. Observations:                3460   AIC:                         8.330e+04\n",
            "Df Residuals:                    3446   BIC:                         8.339e+04\n",
            "Df Model:                          13                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "===================================================================================================\n",
            "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Intercept                       -2326.6814   2319.854     -1.003      0.316   -6875.109    2221.746\n",
            "C(supermarket)[T.supermarket-B] -1.207e+04   1702.643     -7.089      0.000   -1.54e+04   -8731.814\n",
            "C(supermarket)[T.supermarket-D]  1.919e+04   1701.683     11.275      0.000    1.59e+04    2.25e+04\n",
            "C(variant)[T.light]             -1.401e+04   2448.980     -5.722      0.000   -1.88e+04   -9211.823\n",
            "C(variant)[T.standard]           1.169e+04   2201.639      5.312      0.000    7378.122     1.6e+04\n",
            "C(variant)[T.vegan]             -2.291e+04   2580.333     -8.878      0.000    -2.8e+04   -1.78e+04\n",
            "C(pack_size)[T.351 - 500 GR]     3.218e+04   1823.152     17.650      0.000    2.86e+04    3.58e+04\n",
            "C(pack_size)[T.501 - 700 GR]     9762.4943   2531.415      3.857      0.000    4799.269    1.47e+04\n",
            "C(pack_size)[T.701 - 1000 GR]     6.01e+04   2171.125     27.681      0.000    5.58e+04    6.44e+04\n",
            "C(brand)[T.brand-15]             2.941e+04   1820.537     16.152      0.000    2.58e+04     3.3e+04\n",
            "C(brand)[T.brand-35]             7.907e+04   5352.484     14.773      0.000    6.86e+04    8.96e+04\n",
            "C(brand)[T.other]                2.275e+04   4347.703      5.233      0.000    1.42e+04    3.13e+04\n",
            "price:C(brand)[T.brand-35]      -5.863e+04   4770.418    -12.289      0.000    -6.8e+04   -4.93e+04\n",
            "price:C(brand)[T.other]         -1.401e+04   1723.220     -8.130      0.000   -1.74e+04   -1.06e+04\n",
            "==============================================================================\n",
            "Omnibus:                     1982.326   Durbin-Watson:                   2.060\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            30484.953\n",
            "Skew:                           2.409   Prob(JB):                         0.00\n",
            "Kurtosis:                      16.720   Cond. No.                         15.1\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ],
      "source": [
        "model, selected_var, deleted_var = sa.regression_with_backward_elimination(train_data, verbose=True)\n",
        "print(model.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13f17600",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# Funci√≥n para crear variables dummy de intervenci√≥n\n",
        "# ==========================================\n",
        "\n",
        "def add_intervention_dummy(\n",
        "    train_data,\n",
        "    x_train_exogs,\n",
        "    intervention_date,\n",
        "    dummy_name,\n",
        "    brand=None,\n",
        "    supermarkets=None,\n",
        "    variants=None,\n",
        "    pack_sizes=None,\n",
        "    test_data=None,\n",
        "    verbose=True\n",
        "):\n",
        "    \"\"\"\n",
        "    Crea y a√±ade una variable dummy de intervenci√≥n a x_train_exogs.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    train_data : pd.DataFrame\n",
        "        DataFrame de entrenamiento con columnas: date, brand, supermarket, variant, pack.size\n",
        "    x_train_exogs : pd.DataFrame\n",
        "        DataFrame de variables ex√≥genas al que se a√±adir√° la dummy\n",
        "    intervention_date : str or pd.Timestamp\n",
        "        Fecha de intervenci√≥n (formato 'YYYY-MM-DD' o Timestamp)\n",
        "    dummy_name : str\n",
        "        Nombre de la variable dummy (ej: 'intervention_2023_03')\n",
        "    brand : str or list, optional\n",
        "        Marca(s) a filtrar. Si None, no filtra por brand\n",
        "    supermarkets : str or list, optional\n",
        "        Supermercado(s) a filtrar. Si None, no filtra por supermarket\n",
        "    variants : str or list, optional\n",
        "        Variante(s) a filtrar. Si None, no filtra por variant\n",
        "    pack_sizes : str or list, optional\n",
        "        Tama√±o(s) de pack a filtrar. Si None, no filtra por pack.size\n",
        "    test_data : pd.DataFrame, optional\n",
        "        DataFrame de test para crear tambi√©n la dummy en test\n",
        "    verbose : bool, default=True\n",
        "        Si True, imprime informaci√≥n sobre la dummy creada\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    x_train_exogs : pd.DataFrame\n",
        "        DataFrame de variables ex√≥genas con la dummy a√±adida\n",
        "    intervention_dummy_series : pd.Series\n",
        "        Serie con la dummy para train_data\n",
        "    intervention_dummy_test_series : pd.Series or None\n",
        "        Serie con la dummy para test_data (si se proporcion√≥ test_data)\n",
        "    \"\"\"\n",
        "    # Convertir fecha a datetime\n",
        "    if isinstance(intervention_date, str):\n",
        "        intervention_date = pd.to_datetime(intervention_date)\n",
        "    \n",
        "    # Asegurar que train_data['date'] es datetime\n",
        "    train_data = train_data.copy()\n",
        "    train_data['date'] = pd.to_datetime(train_data['date'])\n",
        "    \n",
        "    # Crear condiciones de filtrado\n",
        "    conditions = train_data['date'] >= intervention_date\n",
        "    \n",
        "    if brand is not None:\n",
        "        if isinstance(brand, str):\n",
        "            conditions = conditions & (train_data['brand'] == brand)\n",
        "        else:\n",
        "            conditions = conditions & (train_data['brand'].isin(brand))\n",
        "    \n",
        "    if supermarkets is not None:\n",
        "        if isinstance(supermarkets, str):\n",
        "            conditions = conditions & (train_data['supermarket'] == supermarkets)\n",
        "        else:\n",
        "            conditions = conditions & (train_data['supermarket'].isin(supermarkets))\n",
        "    \n",
        "    if variants is not None:\n",
        "        if isinstance(variants, str):\n",
        "            conditions = conditions & (train_data['variant'] == variants)\n",
        "        else:\n",
        "            conditions = conditions & (train_data['variant'].isin(variants))\n",
        "    \n",
        "    if pack_sizes is not None:\n",
        "        if isinstance(pack_sizes, str):\n",
        "            conditions = conditions & (train_data['pack.size'] == pack_sizes)\n",
        "        else:\n",
        "            conditions = conditions & (train_data['pack.size'].isin(pack_sizes))\n",
        "    \n",
        "    # Crear la dummy para train_data\n",
        "    intervention_dummy = conditions.astype(int)\n",
        "    intervention_dummy_series = pd.Series(\n",
        "        intervention_dummy.values,\n",
        "        index=train_data.index,\n",
        "        name=dummy_name\n",
        "    )\n",
        "    \n",
        "    # Alinear con x_train_exogs\n",
        "    intervention_dummy_aligned = intervention_dummy_series.reindex(x_train_exogs.index, fill_value=0)\n",
        "    \n",
        "    # A√±adir a x_train_exogs\n",
        "    x_train_exogs = pd.concat([x_train_exogs, intervention_dummy_aligned], axis=1)\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"\\n‚úÖ Dummy '{dummy_name}' a√±adida\")\n",
        "        print(f\"   - N√∫mero de 1s: {intervention_dummy_aligned.sum()}\")\n",
        "        print(f\"   - Porcentaje de 1s: {intervention_dummy_aligned.mean()*100:.2f}%\")\n",
        "        print(f\"   - Shape actualizado de X_train_exogs: {x_train_exogs.shape}\")\n",
        "    \n",
        "    # Crear tambi√©n para test_data si se proporciona\n",
        "    intervention_dummy_test_series = None\n",
        "    if test_data is not None:\n",
        "        test_data = test_data.copy()\n",
        "        test_data['date'] = pd.to_datetime(test_data['date'])\n",
        "        \n",
        "        # Crear condiciones para test\n",
        "        conditions_test = test_data['date'] >= intervention_date\n",
        "        \n",
        "        if brand is not None:\n",
        "            if isinstance(brand, str):\n",
        "                conditions_test = conditions_test & (test_data['brand'] == brand)\n",
        "            else:\n",
        "                conditions_test = conditions_test & (test_data['brand'].isin(brand))\n",
        "        \n",
        "        if supermarkets is not None:\n",
        "            if isinstance(supermarkets, str):\n",
        "                conditions_test = conditions_test & (test_data['supermarket'] == supermarkets)\n",
        "            else:\n",
        "                conditions_test = conditions_test & (test_data['supermarket'].isin(supermarkets))\n",
        "        \n",
        "        if variants is not None:\n",
        "            if isinstance(variants, str):\n",
        "                conditions_test = conditions_test & (test_data['variant'] == variants)\n",
        "            else:\n",
        "                conditions_test = conditions_test & (test_data['variant'].isin(variants))\n",
        "        \n",
        "        if pack_sizes is not None:\n",
        "            if isinstance(pack_sizes, str):\n",
        "                conditions_test = conditions_test & (test_data['pack.size'] == pack_sizes)\n",
        "            else:\n",
        "                conditions_test = conditions_test & (test_data['pack.size'].isin(pack_sizes))\n",
        "        \n",
        "        intervention_dummy_test = conditions_test.astype(int)\n",
        "        intervention_dummy_test_series = pd.Series(\n",
        "            intervention_dummy_test.values,\n",
        "            index=test_data.index,\n",
        "            name=dummy_name\n",
        "        )\n",
        "        \n",
        "        if verbose:\n",
        "            print(f\"   - Test data: {intervention_dummy_test_series.sum()} observaciones con 1\")\n",
        "    \n",
        "    return x_train_exogs, intervention_dummy_series, intervention_dummy_test_series\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c21c9792",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Celda eliminada - la llamada a add_intervention_dummy()\n",
        "# debe ir DESPU√âS de crear x_train_exogs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "feba18b8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ YES - All features match perfectly!\n",
            "\n",
            "Shape de X_train_exox: (3460, 13)\n",
            "Columnas:\n",
            "C(supermarket)[T.supermarket-B]\n",
            "C(supermarket)[T.supermarket-D]\n",
            "C(variant)[T.light]\n",
            "C(variant)[T.standard]\n",
            "C(variant)[T.vegan]\n",
            "C(pack_size)[T.351 - 500 GR]\n",
            "C(pack_size)[T.501 - 700 GR]\n",
            "C(pack_size)[T.701 - 1000 GR]\n",
            "C(brand)[T.brand-15]\n",
            "C(brand)[T.brand-35]\n",
            "C(brand)[T.other]\n",
            "price:C(brand)[T.brand-35]\n",
            "price:C(brand)[T.other]\n"
          ]
        }
      ],
      "source": [
        "x_train_exogs = sa.x_train_exog_custom(train_data, selected_var, model)\n",
        "print(f\"\\nShape de X_train_exox: {x_train_exogs.shape}\")\n",
        "print(\"Columnas:\")\n",
        "for col in x_train_exogs.columns:\n",
        "    print(col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25645b18",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ Variable dummy de intervenci√≥n a√±adida\n",
            "   - Nombre: intervention_2023_03\n",
            "   - Valores √∫nicos: [0 1]\n",
            "   - N√∫mero de 1s (intervenci√≥n activa): 23\n",
            "   - Porcentaje de 1s: 0.66%\n",
            "\n",
            "Shape actualizado de X_train_exogs: (3460, 15)\n",
            "Columnas: ['C(supermarket)[T.supermarket-B]', 'C(supermarket)[T.supermarket-D]', 'C(variant)[T.light]', 'C(variant)[T.standard]', 'C(variant)[T.vegan]', 'C(pack_size)[T.351 - 500 GR]', 'C(pack_size)[T.501 - 700 GR]', 'C(pack_size)[T.701 - 1000 GR]', 'C(brand)[T.brand-15]', 'C(brand)[T.brand-35]', 'C(brand)[T.other]', 'price:C(brand)[T.brand-35]', 'price:C(brand)[T.other]', 'intervention_2023_03_brand15_BC_vegan', 'intervention_2023_03']\n",
            "\n",
            "‚úÖ Variable dummy de intervenci√≥n tambi√©n creada para test_data\n",
            "   - N√∫mero de 1s en test_data: 28\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# Crear variables dummy de intervenci√≥n usando la funci√≥n\n",
        "# ==========================================\n",
        "\n",
        "# Dummy 1: Marzo 2023\n",
        "x_train_exogs, dummy_03_train, dummy_03_test = add_intervention_dummy(\n",
        "    train_data=train_data,\n",
        "    x_train_exogs=x_train_exogs,\n",
        "    intervention_date='2023-03-31',\n",
        "    dummy_name='intervention_2023_03',\n",
        "    brand='brand-15',\n",
        "    supermarkets=['supermarket-B', 'supermarket-C', 'supermarket-D'],\n",
        "    variants=['vegan', 'light'],\n",
        "    pack_sizes=['351 - 500 GR', '501 - 700 GR'],\n",
        "    test_data=test_data if 'test_data' in globals() else None,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Dummy 2: Junio 2023\n",
        "x_train_exogs, dummy_06_train, dummy_06_test = add_intervention_dummy(\n",
        "    train_data=train_data,\n",
        "    x_train_exogs=x_train_exogs,\n",
        "    intervention_date='2023-06-30',\n",
        "    dummy_name='intervention_2023_06',\n",
        "    brand='brand-15',\n",
        "    supermarkets=['supermarket-B', 'supermarket-C', 'supermarket-D'],\n",
        "    variants=['vegan', 'light'],\n",
        "    pack_sizes=['351 - 500 GR', '501 - 700 GR'],\n",
        "    test_data=test_data if 'test_data' in globals() else None,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(f\"\\nüìä Resumen final:\")\n",
        "print(f\"   - Shape de X_train_exogs: {x_train_exogs.shape}\")\n",
        "print(f\"   - Columnas de intervenci√≥n: {[col for col in x_train_exogs.columns if 'intervention' in col]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6e696b68",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Verificaci√≥n de variables ex√≥genas:\n",
            "  - x_train_exogs tiene 14 columnas\n",
            "  - √öltima columna a√±adida: intervention_2023_03_brand15_BC_vegan\n"
          ]
        }
      ],
      "source": [
        "# Verificaci√≥n simple: la dummy est√° en x_train_exogs\n",
        "print(\"Verificaci√≥n de variables ex√≥genas:\")\n",
        "print(f\"  - x_train_exogs tiene {x_train_exogs.shape[1]} columnas\")\n",
        "print(f\"  - √öltima columna a√±adida: {x_train_exogs.columns[-1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4c3bde9",
      "metadata": {},
      "source": [
        "2. Diagn√≥stico de las variables ex√≥genas "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "dd4fdc4e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "### Diagn√≥stico ex√≥genas\n",
            "- Observaciones (tras dropna): 3460\n",
            "- N√∫mero de ex√≥genas: 14\n",
            "\n",
            "## 1) Calidad b√°sica\n",
            "- Missing rate (top 10):\n",
            "C(supermarket)[T.supermarket-B]    0.0\n",
            "C(supermarket)[T.supermarket-D]    0.0\n",
            "C(variant)[T.light]                0.0\n",
            "C(variant)[T.standard]             0.0\n",
            "C(variant)[T.vegan]                0.0\n",
            "C(pack_size)[T.351 - 500 GR]       0.0\n",
            "C(pack_size)[T.501 - 700 GR]       0.0\n",
            "C(pack_size)[T.701 - 1000 GR]      0.0\n",
            "C(brand)[T.brand-15]               0.0\n",
            "C(brand)[T.brand-35]               0.0\n",
            "dtype: float64\n",
            "\n",
            "- OK: no hay variables constantes (nunique<=1)\n",
            "\n",
            "- Std (min 10):\n",
            "intervention_2023_03_brand15_BC_vegan    0.056303\n",
            "C(pack_size)[T.501 - 700 GR]             0.331910\n",
            "C(variant)[T.vegan]                      0.347516\n",
            "C(brand)[T.brand-35]                     0.392495\n",
            "C(brand)[T.other]                        0.410299\n",
            "C(pack_size)[T.701 - 1000 GR]            0.412496\n",
            "price:C(brand)[T.brand-35]               0.429781\n",
            "C(supermarket)[T.supermarket-B]          0.441412\n",
            "C(supermarket)[T.supermarket-D]          0.444888\n",
            "C(pack_size)[T.351 - 500 GR]             0.453237\n",
            "dtype: float64\n",
            "\n",
            "## 2) Multicolinealidad (VIF)\n",
            "C(brand)[T.brand-35]                     9.167571\n",
            "price:C(brand)[T.brand-35]               8.731613\n",
            "C(brand)[T.other]                        6.610538\n",
            "price:C(brand)[T.other]                  5.897565\n",
            "C(variant)[T.light]                      2.617158\n",
            "C(variant)[T.standard]                   2.388698\n",
            "C(variant)[T.vegan]                      1.686462\n",
            "C(pack_size)[T.701 - 1000 GR]            1.666042\n",
            "C(brand)[T.brand-15]                     1.496352\n",
            "C(pack_size)[T.501 - 700 GR]             1.466376\n",
            "C(pack_size)[T.351 - 500 GR]             1.418478\n",
            "C(supermarket)[T.supermarket-D]          1.191942\n",
            "C(supermarket)[T.supermarket-B]          1.173482\n",
            "intervention_2023_03_brand15_BC_vegan    1.027093\n",
            "dtype: float64\n",
            "\n",
            "- Regla r√°pida: VIF>10 suele indicar colinealidad fuerte (revisar/regularizar).\n",
            "\n",
            "## 3) Correlaci√≥n contempor√°nea con y\n",
            "- Corr(X, y) ordenadas por |corr| (top 15):\n",
            "C(pack_size)[T.701 - 1000 GR]            0.236340\n",
            "C(pack_size)[T.351 - 500 GR]             0.205569\n",
            "price:C(brand)[T.other]                 -0.204018\n",
            "C(brand)[T.brand-15]                     0.188215\n",
            "C(brand)[T.other]                       -0.169048\n",
            "C(variant)[T.vegan]                     -0.149138\n",
            "C(variant)[T.standard]                   0.140444\n",
            "C(supermarket)[T.supermarket-B]         -0.125572\n",
            "C(brand)[T.brand-35]                     0.092523\n",
            "price:C(brand)[T.brand-35]               0.073319\n",
            "C(supermarket)[T.supermarket-D]          0.070590\n",
            "C(pack_size)[T.501 - 700 GR]            -0.056486\n",
            "intervention_2023_03_brand15_BC_vegan   -0.017847\n",
            "C(variant)[T.light]                     -0.007398\n",
            "dtype: float64\n",
            "\n",
            "## 4) Correlaci√≥n cruzada con rezagos\n",
            "- Top 20 (|corr|) de X(t-lag) vs y(t):\n",
            "                                 variable  lag      corr\n",
            "49          C(pack_size)[T.701 - 1000 GR]    0  0.236340\n",
            "35           C(pack_size)[T.351 - 500 GR]    0  0.205569\n",
            "84                price:C(brand)[T.other]    0 -0.204018\n",
            "56                   C(brand)[T.brand-15]    0  0.188215\n",
            "70                      C(brand)[T.other]    0 -0.169048\n",
            "28                    C(variant)[T.vegan]    0 -0.149138\n",
            "21                 C(variant)[T.standard]    0  0.140444\n",
            "0         C(supermarket)[T.supermarket-B]    0 -0.125572\n",
            "63                   C(brand)[T.brand-35]    0  0.092523\n",
            "77             price:C(brand)[T.brand-35]    0  0.073319\n",
            "7         C(supermarket)[T.supermarket-D]    0  0.070590\n",
            "42           C(pack_size)[T.501 - 700 GR]    0 -0.056486\n",
            "10        C(supermarket)[T.supermarket-D]    3 -0.052283\n",
            "27                 C(variant)[T.standard]    6 -0.044455\n",
            "34                    C(variant)[T.vegan]    6  0.038095\n",
            "57                   C(brand)[T.brand-15]    1  0.035680\n",
            "30                    C(variant)[T.vegan]    2  0.034283\n",
            "96  intervention_2023_03_brand15_BC_vegan    5 -0.032900\n",
            "62                   C(brand)[T.brand-15]    6  0.032523\n",
            "23                 C(variant)[T.standard]    2 -0.031020\n",
            "\n",
            "## 5) Estacionariedad (ADF/KPSS)\n",
            "(Nota: en dummies puede no ser muy informativo, pero es √∫til para interacciones/continuas.)\n",
            "- p-valores (ADF: peque√±o => estacionaria; KPSS: grande => estacionaria).\n",
            "                                              p_adf    p_kpss\n",
            "variable                                                     \n",
            "C(variant)[T.vegan]                    0.000000e+00  0.067366\n",
            "C(supermarket)[T.supermarket-B]        0.000000e+00  0.100000\n",
            "C(supermarket)[T.supermarket-D]        0.000000e+00  0.100000\n",
            "C(variant)[T.standard]                 0.000000e+00  0.100000\n",
            "C(pack_size)[T.351 - 500 GR]           0.000000e+00  0.100000\n",
            "C(pack_size)[T.501 - 700 GR]           0.000000e+00  0.100000\n",
            "C(pack_size)[T.701 - 1000 GR]          0.000000e+00  0.100000\n",
            "C(brand)[T.brand-15]                   0.000000e+00  0.100000\n",
            "C(brand)[T.brand-35]                   0.000000e+00  0.100000\n",
            "C(brand)[T.other]                      0.000000e+00  0.100000\n",
            "price:C(brand)[T.brand-35]             0.000000e+00  0.100000\n",
            "price:C(brand)[T.other]                0.000000e+00  0.100000\n",
            "C(variant)[T.light]                    2.332022e-25  0.100000\n",
            "intervention_2023_03_brand15_BC_vegan  1.812844e-12  0.010000\n",
            "\n",
            "## 6) Granger (screening r√°pido)\n",
            "(Ojo: depende de supuestos y de la frecuencia; √∫salo como se√±al, no como verdad absoluta.)\n",
            "- Mejor p-valor (m√≠nimo) por variable entre lags 1..maxlag:\n",
            "C(brand)[T.brand-15]               0.050900\n",
            "C(variant)[T.standard]             0.055647\n",
            "C(pack_size)[T.351 - 500 GR]       0.068343\n",
            "C(variant)[T.vegan]                0.112190\n",
            "C(pack_size)[T.701 - 1000 GR]      0.113352\n",
            "price:C(brand)[T.other]            0.216497\n",
            "C(brand)[T.other]                  0.279361\n",
            "C(supermarket)[T.supermarket-B]    0.329086\n",
            "dtype: float64\n",
            "\n",
            "### Interpretaci√≥n r√°pida\n",
            "- Si una variable tiene VIF muy alto, puede desestabilizar el ARIMAX (coeficientes err√°ticos).\n",
            "- Si una variable no muestra ninguna relaci√≥n (corr ~0 en todos los lags), suele aportar poco.\n",
            "- Si ADF/KPSS indican no-estacionariedad en continuas, considera diferenciar/transformar esa ex√≥gena.\n",
            "- Granger con p peque√±o puede sugerir se√±al predictiva (pero revisa siempre con backtesting).\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# Diagn√≥stico de variables ex√≥genas (ARIMAX)\n",
        "# Objetivo: evaluar si las ex√≥genas aportan se√±al √∫til y si son ‚Äúseguras‚Äù (sin\n",
        "# problemas graves de colinealidad / no estacionariedad / mala calidad).\n",
        "# ==========================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from statsmodels.tsa.stattools import adfuller, kpss, grangercausalitytests\n",
        "\n",
        "# --- Selecci√≥n de y (alineada con X) ---\n",
        "# Intentamos usar la serie transformada (Box-Cox) si existe; si no, usamos la y original.\n",
        "if \"y_train_boxcox\" in globals() and y_train_boxcox is not None:\n",
        "    y_diag = pd.Series(y_train_boxcox, index=train_data.index, name=\"y_train_boxcox\")\n",
        "else:\n",
        "    y_diag = pd.Series(train_data[\"volume_sales\"], index=train_data.index, name=\"volume_sales\")\n",
        "\n",
        "# Alineaci√≥n estricta X/y (mismo √≠ndice, sin NaNs)\n",
        "X_diag = x_train_exogs.copy()\n",
        "df_diag = pd.concat([y_diag, X_diag], axis=1).replace([np.inf, -np.inf], np.nan).dropna(axis=0)\n",
        "\n",
        "y_diag = df_diag.iloc[:, 0]\n",
        "X_diag = df_diag.iloc[:, 1:]\n",
        "\n",
        "print(\"\\n### Diagn√≥stico ex√≥genas\")\n",
        "print(f\"- Observaciones (tras dropna): {len(df_diag)}\")\n",
        "print(f\"- N√∫mero de ex√≥genas: {X_diag.shape[1]}\")\n",
        "\n",
        "# --- 1) Calidad b√°sica: missing, constantes, varianza ---\n",
        "print(\"\\n## 1) Calidad b√°sica\")\n",
        "missing = x_train_exogs.isna().mean().sort_values(ascending=False)\n",
        "print(\"- Missing rate (top 10):\")\n",
        "print(missing.head(10))\n",
        "\n",
        "nunique = X_diag.nunique(dropna=True).sort_values()\n",
        "const_like = nunique[nunique <= 1]\n",
        "if len(const_like) > 0:\n",
        "    print(\"\\n- Variables constantes/casi constantes (nunique<=1):\")\n",
        "    print(const_like)\n",
        "else:\n",
        "    print(\"\\n- OK: no hay variables constantes (nunique<=1)\")\n",
        "\n",
        "stds = X_diag.std(numeric_only=True).sort_values()\n",
        "print(\"\\n- Std (min 10):\")\n",
        "print(stds.head(10))\n",
        "\n",
        "# --- 2) Multicolinealidad (VIF) ---\n",
        "print(\"\\n## 2) Multicolinealidad (VIF)\")\n",
        "# VIF requiere matriz num√©rica; a√±adimos constante para estabilidad\n",
        "X_vif = X_diag.astype(float)\n",
        "X_vif_const = np.column_stack([np.ones(len(X_vif)), X_vif.values])\n",
        "\n",
        "vif_vals = []\n",
        "cols = [\"const\"] + list(X_vif.columns)\n",
        "for i in range(len(cols)):\n",
        "    try:\n",
        "        vif_vals.append(variance_inflation_factor(X_vif_const, i))\n",
        "    except Exception:\n",
        "        vif_vals.append(np.nan)\n",
        "\n",
        "vif = pd.Series(vif_vals, index=cols).drop(\"const\", errors=\"ignore\").sort_values(ascending=False)\n",
        "print(vif)\n",
        "print(\"\\n- Regla r√°pida: VIF>10 suele indicar colinealidad fuerte (revisar/regularizar).\")\n",
        "\n",
        "# --- 3) Correlaci√≥n contempor√°nea con y (se√±al lineal) ---\n",
        "print(\"\\n## 3) Correlaci√≥n contempor√°nea con y\")\n",
        "# Pearson sobre variables num√©ricas (aqu√≠ son dummies e interacciones num√©ricas)\n",
        "cor_y = X_diag.apply(lambda s: s.corr(y_diag), axis=0).sort_values(key=lambda s: s.abs(), ascending=False)\n",
        "print(\"- Corr(X, y) ordenadas por |corr| (top 15):\")\n",
        "print(cor_y.head(15))\n",
        "\n",
        "# --- 4) Correlaci√≥n cruzada con rezagos (si las ex√≥genas ‚Äúanticipan‚Äù a y) ---\n",
        "print(\"\\n## 4) Correlaci√≥n cruzada con rezagos\")\n",
        "max_lag = 6  # ajusta si trabajas mensual (p.ej. 12)\n",
        "ccf_rows = []\n",
        "for col in X_diag.columns:\n",
        "    for lag in range(0, max_lag + 1):\n",
        "        # correlaci√≥n de X(t-lag) con y(t): si lag>0, X antecede a y\n",
        "        c = X_diag[col].shift(lag).corr(y_diag)\n",
        "        ccf_rows.append((col, lag, c))\n",
        "\n",
        "ccf = pd.DataFrame(ccf_rows, columns=[\"variable\", \"lag\", \"corr\"])\n",
        "ccf[\"abs_corr\"] = ccf[\"corr\"].abs()\n",
        "print(\"- Top 20 (|corr|) de X(t-lag) vs y(t):\")\n",
        "print(ccf.sort_values(\"abs_corr\", ascending=False).head(20).drop(columns=[\"abs_corr\"]))\n",
        "\n",
        "# --- 5) Estacionariedad (ADF/KPSS) ---\n",
        "print(\"\\n## 5) Estacionariedad (ADF/KPSS)\\n(Nota: en dummies puede no ser muy informativo, pero es √∫til para interacciones/continuas.)\")\n",
        "\n",
        "def _adf(series):\n",
        "    try:\n",
        "        res = adfuller(series.values, autolag=\"AIC\")\n",
        "        return res[1]\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "\n",
        "def _kpss(series):\n",
        "    try:\n",
        "        res = kpss(series.values, regression=\"c\", nlags=\"auto\")\n",
        "        return res[1]\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "\n",
        "st_rows = []\n",
        "for col in X_diag.columns:\n",
        "    s = X_diag[col].astype(float)\n",
        "    st_rows.append((col, _adf(s), _kpss(s)))\n",
        "\n",
        "stationarity = pd.DataFrame(st_rows, columns=[\"variable\", \"p_adf\", \"p_kpss\"]).set_index(\"variable\")\n",
        "print(\"- p-valores (ADF: peque√±o => estacionaria; KPSS: grande => estacionaria).\")\n",
        "print(stationarity.sort_values([\"p_adf\", \"p_kpss\"]))\n",
        "\n",
        "# --- 6) Granger (muy r√°pido) ---\n",
        "print(\"\\n## 6) Granger (screening r√°pido)\\n(Ojo: depende de supuestos y de la frecuencia; √∫salo como se√±al, no como verdad absoluta.)\")\n",
        "maxlag_granger = 6\n",
        "pvals = []\n",
        "\n",
        "# Para evitar explosi√≥n de tiempo, hacemos Granger solo con las top variables por |corr| contempor√°nea\n",
        "topk = min(8, X_diag.shape[1])\n",
        "top_vars = list(cor_y.head(topk).index)\n",
        "\n",
        "for col in top_vars:\n",
        "    tmp = pd.concat([y_diag, X_diag[col]], axis=1)\n",
        "    tmp.columns = [\"y\", \"x\"]\n",
        "    try:\n",
        "        # test: ¬øx causa a y?\n",
        "        res = grangercausalitytests(tmp[[\"y\", \"x\"]], maxlag=maxlag_granger, verbose=False)\n",
        "        # tomamos el mejor (m√≠nimo) p-valor del test ssr_ftest en todos los lags\n",
        "        best_p = np.min([res[i+1][0][\"ssr_ftest\"][1] for i in range(maxlag_granger)])\n",
        "        pvals.append((col, best_p))\n",
        "    except Exception:\n",
        "        pvals.append((col, np.nan))\n",
        "\n",
        "granger_screen = pd.Series(dict(pvals)).sort_values()\n",
        "print(\"- Mejor p-valor (m√≠nimo) por variable entre lags 1..maxlag:\")\n",
        "print(granger_screen)\n",
        "\n",
        "print(\"\\n### Interpretaci√≥n r√°pida\")\n",
        "print(\"- Si una variable tiene VIF muy alto, puede desestabilizar el ARIMAX (coeficientes err√°ticos).\")\n",
        "print(\"- Si una variable no muestra ninguna relaci√≥n (corr ~0 en todos los lags), suele aportar poco.\")\n",
        "print(\"- Si ADF/KPSS indican no-estacionariedad en continuas, considera diferenciar/transformar esa ex√≥gena.\")\n",
        "print(\"- Granger con p peque√±o puede sugerir se√±al predictiva (pero revisa siempre con backtesting).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d91761e",
      "metadata": {},
      "source": [
        "‚ÄºÔ∏è Probar a quitar las variables C(brand)[T.brand-35] ~9.14 y price:C(brand)[T.brand-35] ~8.71, para ver si el forecast mejora"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0fa705f",
      "metadata": {},
      "source": [
        "Diagn√≥stico:\n",
        "\n",
        "1) Calidad b√°sica\n",
        "M√©trica\tTu resultado\tInterpretaci√≥n\n",
        "Missing rate\t0.0 en todas\tPerfecto: no hay valores faltantes en ninguna ex√≥gena.\n",
        "Variables constantes\tNinguna\tOK: todas var√≠an suficiente (si alguna fuera constante, no aportar√≠a nada al modelo).\n",
        "Std (desviaci√≥n)\t0.33 ‚Äì 0.49\tRango razonable para dummies/interacciones. Valores muy cercanos a 0 ser√≠an sospechosos.\n",
        "Conclusi√≥n secci√≥n 1: Las ex√≥genas est√°n \"limpias\" en t√©rminos de calidad de datos.\n",
        "2) Multicolinealidad (VIF)\n",
        "Variable\tVIF\n",
        "C(brand)[T.brand-35]\t9.14\n",
        "price:C(brand)[T.brand-35]\t8.71\n",
        "C(brand)[T.other]\t6.60\n",
        "price:C(brand)[T.other]\t5.88\n",
        "Resto\t< 3\n",
        "Regla pr√°ctica:\n",
        "VIF < 5 ‚Üí sin problema.\n",
        "5 ‚â§ VIF < 10 ‚Üí colinealidad moderada, vigila.\n",
        "VIF ‚â• 10 ‚Üí colinealidad fuerte, puede desestabilizar coeficientes.\n",
        "Tu caso: brand-35 y su interacci√≥n price:brand-35 est√°n justo al l√≠mite (~9). Esto ocurre porque la interacci√≥n price √ó brand-35 est√° muy correlacionada con la dummy brand-35 (cuando brand-35 = 0, la interacci√≥n tambi√©n es 0). No es cr√≠tico, pero podr√≠as:\n",
        "Probar a quitar una de las dos (como ya anotaste).\n",
        "O usar regularizaci√≥n (Ridge/Lasso) si entrenas un modelo lineal auxiliar.\n",
        "3) Correlaci√≥n contempor√°nea con y\n",
        "Variable\tcorr(X, y)\n",
        "pack_size 701-1000 GR\t+0.24\n",
        "price:brand-other\t‚àí0.21\n",
        "pack_size 351-500 GR\t+0.21\n",
        "brand-15\t+0.19\n",
        "brand-other\t‚àí0.17\n",
        "...\t...\n",
        "variant-light\t‚àí0.008 (casi 0)\n",
        "Interpretaci√≥n:\n",
        "Correlaciones de ¬±0.15‚Äì0.25 son modestas pero √∫tiles en un ARIMAX (la se√±al principal viene del componente AR/MA).\n",
        "variant-light con corr ‚âà 0 aporta poca se√±al lineal directa; podr√≠as plantearte si vale la pena incluirla.\n",
        "4) Correlaci√≥n cruzada con rezagos\n",
        "Muestra corr(X(t‚àílag), y(t)) para detectar si alguna ex√≥gena anticipa a la variable objetivo.\n",
        "Tu resultado: las correlaciones m√°s altas est√°n en lag = 0 (contempor√°neas). A medida que subes el lag (1, 2, ‚Ä¶, 6), las correlaciones caen mucho (< 0.05).\n",
        "Interpretaci√≥n: tus ex√≥genas explican ventas en el mismo per√≠odo, pero no tienen poder predictivo adelantado relevante. Esto es normal en datos de panel/cross-section donde las ex√≥genas son caracter√≠sticas del producto en el mismo mes.\n",
        "5) Estacionariedad (ADF / KPSS)\n",
        "Test\tp-valor peque√±o significa‚Ä¶\n",
        "ADF\tSerie estacionaria (rechazas ra√≠z unitaria).\n",
        "KPSS\tSerie no estacionaria (rechazas estacionariedad).\n",
        "Tu resultado:\n",
        "p_adf ‚âà 0 en todas ‚Üí todas pasan ADF (estacionarias).\n",
        "p_kpss = 0.10 (el m√°ximo que reporta) ‚Üí no rechazas estacionariedad.\n",
        "Conclusi√≥n: Todas las ex√≥genas se comportan como estacionarias. Esto es esperable en dummies (0/1) e interacciones acotadas. No necesitas diferenciarlas.\n",
        "6) Granger (screening r√°pido)\n",
        "Prueba si los rezagos de X ayudan a predecir y m√°s all√° de los propios rezagos de y.\n",
        "Variable\tMejor p-valor\n",
        "supermarket-B\t0.068\n",
        "pack_size 701-1000 GR\t0.13\n",
        "Resto\t> 0.25\n",
        "Interpretaci√≥n:\n",
        "Ninguna alcanza p < 0.05, as√≠ que ninguna muestra causalidad Granger significativa.\n",
        "Esto confirma lo de la secci√≥n 4: las ex√≥genas son √∫tiles contempor√°neamente, pero sus rezagos no aportan poder predictivo extra.\n",
        "En un ARIMAX esto no es un problema grave: el modelo usa las ex√≥genas en t para explicar y(t), no necesita que X(t‚àí1) prediga y(t).\n",
        "Resumen ejecutivo\n",
        "Aspecto\tVeredicto\n",
        "Calidad datos\t‚úÖ Sin missing ni constantes\n",
        "Colinealidad\t‚ö†Ô∏è brand-35 y su interacci√≥n rozan VIF=10. Prueba quitarlas para ver si mejora.\n",
        "Se√±al lineal\t‚úÖ Correlaciones modestas pero razonables (0.1‚Äì0.24)\n",
        "Se√±al adelantada\t‚ùå No hay; ex√≥genas solo informan en t, no anticipan\n",
        "Estacionariedad\t‚úÖ Todas estacionarias\n",
        "Granger\t‚ùå Sin causalidad significativa (esperable en cross-section)\n",
        "Recomendaci√≥n pr√°ctica: prueba dos versiones del ARIMAX:\n",
        "Con todas las ex√≥genas actuales.\n",
        "Quitando C(brand)[T.brand-35] y price:C(brand)[T.brand-35] (las de VIF alto).\n",
        "Compara m√©tricas de forecast (MAPE, RMSE) en el conjunto de test para decidir cu√°l funciona mejor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9d6f8681",
      "metadata": {},
      "outputs": [],
      "source": [
        "if False:\n",
        "    # Elimina las columnas 'C(brand)[T.brand-35]' y 'price:C(brand)[T.brand-35]' de x_train_exogs si existen\n",
        "    x_train_exogs = x_train_exogs.drop(columns=[col for col in ['C(brand)[T.brand-35]', 'price:C(brand)[T.brand-35]'] if col in x_train_exogs.columns])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "672b7e72",
      "metadata": {},
      "source": [
        "3. Realizamos el modelo ARIMAX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "bb15e192",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performing stepwise search to minimize aic\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m autoarimax_model \u001b[38;5;241m=\u001b[39m \u001b[43mauto_arima\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train_boxcox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train_exogs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_q\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_q\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_P\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mD\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#TODO: probar a usar D=0\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43msart_Q\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_P\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_Q\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseasonal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwarn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43msuppress_warnings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstepwise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_fits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43minformation_criterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maic\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(autoarimax_model\u001b[38;5;241m.\u001b[39msummary())\n",
            "File \u001b[0;32m~/Documents/TFG_ADE/code/TFG/lib/python3.9/site-packages/pmdarima/arima/auto.py:701\u001b[0m, in \u001b[0;36mauto_arima\u001b[0;34m(y, X, start_p, d, start_q, max_p, max_d, max_q, start_P, D, start_Q, max_P, max_D, max_Q, max_order, m, seasonal, stationary, information_criterion, alpha, test, seasonal_test, stepwise, n_jobs, start_params, trend, method, maxiter, offset_test_args, seasonal_test_args, suppress_warnings, error_action, trace, random, random_state, n_fits, return_valid_fits, out_of_sample_size, scoring, scoring_args, with_intercept, sarimax_kwargs, **fit_args)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[38;5;66;03m# init the stepwise model wrapper\u001b[39;00m\n\u001b[1;32m    670\u001b[0m     search \u001b[38;5;241m=\u001b[39m solvers\u001b[38;5;241m.\u001b[39m_StepwiseFitWrapper(\n\u001b[1;32m    671\u001b[0m         y,\n\u001b[1;32m    672\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msarimax_kwargs,\n\u001b[1;32m    699\u001b[0m     )\n\u001b[0;32m--> 701\u001b[0m sorted_res \u001b[38;5;241m=\u001b[39m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _return_wrapper(sorted_res, return_valid_fits, start, trace)\n",
            "File \u001b[0;32m~/Documents/TFG_ADE/code/TFG/lib/python3.9/site-packages/pmdarima/arima/_auto_solvers.py:288\u001b[0m, in \u001b[0;36m_StepwiseFitWrapper.solve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerforming stepwise search to minimize \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m           \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minformation_criterion)\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# fit a baseline p, d, q model\u001b[39;00m\n\u001b[0;32m--> 288\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# null model with possible constant\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_fit((\u001b[38;5;241m0\u001b[39m, d, \u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m0\u001b[39m, D, \u001b[38;5;241m0\u001b[39m, m)):\n",
            "File \u001b[0;32m~/Documents/TFG_ADE/code/TFG/lib/python3.9/site-packages/pmdarima/arima/_auto_solvers.py:235\u001b[0m, in \u001b[0;36m_StepwiseFitWrapper._do_fit\u001b[0;34m(self, order, seasonal_order, constant)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (order, seasonal_order, constant) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults_dict:\n\u001b[1;32m    231\u001b[0m \n\u001b[1;32m    232\u001b[0m     \u001b[38;5;66;03m# increment the number of fits\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 235\u001b[0m     fit, fit_time, new_ic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_arima\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseasonal_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseasonal_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# use the orders as a key to be hashed for\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# the dictionary (pointing to fit)\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults_dict[(order, seasonal_order, constant)] \u001b[38;5;241m=\u001b[39m fit\n",
            "File \u001b[0;32m~/Documents/TFG_ADE/code/TFG/lib/python3.9/site-packages/pmdarima/arima/_auto_solvers.py:508\u001b[0m, in \u001b[0;36m_fit_candidate_model\u001b[0;34m(y, X, order, seasonal_order, start_params, trend, method, maxiter, fit_params, suppress_warnings, trace, error_action, out_of_sample_size, scoring, scoring_args, with_intercept, information_criterion, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m fit \u001b[38;5;241m=\u001b[39m ARIMA(order\u001b[38;5;241m=\u001b[39morder, seasonal_order\u001b[38;5;241m=\u001b[39mseasonal_order,\n\u001b[1;32m    501\u001b[0m             start_params\u001b[38;5;241m=\u001b[39mstart_params, trend\u001b[38;5;241m=\u001b[39mtrend, method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    502\u001b[0m             maxiter\u001b[38;5;241m=\u001b[39mmaxiter, suppress_warnings\u001b[38;5;241m=\u001b[39msuppress_warnings,\n\u001b[1;32m    503\u001b[0m             out_of_sample_size\u001b[38;5;241m=\u001b[39mout_of_sample_size, scoring\u001b[38;5;241m=\u001b[39mscoring,\n\u001b[1;32m    504\u001b[0m             scoring_args\u001b[38;5;241m=\u001b[39mscoring_args,\n\u001b[1;32m    505\u001b[0m             with_intercept\u001b[38;5;241m=\u001b[39mwith_intercept, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 508\u001b[0m     \u001b[43mfit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# for non-stationarity errors or singular matrices, return None\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (LinAlgError, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m v:\n",
            "File \u001b[0;32m~/Documents/TFG_ADE/code/TFG/lib/python3.9/site-packages/pmdarima/arima/arima.py:603\u001b[0m, in \u001b[0;36mARIMA.fit\u001b[0;34m(self, y, X, **fit_args)\u001b[0m\n\u001b[1;32m    600\u001b[0m         X \u001b[38;5;241m=\u001b[39m safe_indexing(X, \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m0\u001b[39m, n_exog \u001b[38;5;241m-\u001b[39m cv))\n\u001b[1;32m    602\u001b[0m \u001b[38;5;66;03m# Internal call\u001b[39;00m\n\u001b[0;32m--> 603\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;66;03m# now make a forecast if we're validating to compute the\u001b[39;00m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;66;03m# out-of-sample score\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv_samples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;66;03m# get the predictions (use self.predict, which calls forecast\u001b[39;00m\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;66;03m# from statsmodels internally)\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/TFG_ADE/code/TFG/lib/python3.9/site-packages/pmdarima/arima/arima.py:524\u001b[0m, in \u001b[0;36mARIMA._fit\u001b[0;34m(self, y, X, **fit_args)\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    523\u001b[0m         warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 524\u001b[0m         fit, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marima_res_ \u001b[38;5;241m=\u001b[39m \u001b[43m_fit_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    526\u001b[0m     fit, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marima_res_ \u001b[38;5;241m=\u001b[39m _fit_wrapper()\n",
            "File \u001b[0;32m~/Documents/TFG_ADE/code/TFG/lib/python3.9/site-packages/pmdarima/arima/arima.py:510\u001b[0m, in \u001b[0;36mARIMA._fit.<locals>._fit_wrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m    507\u001b[0m _maxiter \u001b[38;5;241m=\u001b[39m fit_args\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m\"\u001b[39m, _maxiter)\n\u001b[1;32m    509\u001b[0m disp \u001b[38;5;241m=\u001b[39m fit_args\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 510\u001b[0m fitted \u001b[38;5;241m=\u001b[39m \u001b[43marima\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_maxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arima, fitted\n",
            "File \u001b[0;32m~/Documents/TFG_ADE/code/TFG/lib/python3.9/site-packages/statsmodels/tsa/statespace/mlemodel.py:705\u001b[0m, in \u001b[0;36mMLEModel.fit\u001b[0;34m(self, start_params, transformed, includes_fixed, cov_type, cov_kwds, method, maxiter, full_output, disp, callback, return_params, optim_score, optim_complex_step, optim_hessian, flags, low_memory, **kwargs)\u001b[0m\n\u001b[1;32m    703\u001b[0m         flags[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhessian_method\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m optim_hessian\n\u001b[1;32m    704\u001b[0m     fargs \u001b[38;5;241m=\u001b[39m (flags,)\n\u001b[0;32m--> 705\u001b[0m     mlefit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mskip_hessian\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;66;03m# Just return the fitted parameters if requested\u001b[39;00m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_params:\n",
            "File \u001b[0;32m~/Documents/TFG_ADE/code/TFG/lib/python3.9/site-packages/statsmodels/base/model.py:566\u001b[0m, in \u001b[0;36mLikelihoodModel.fit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_t\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    565\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Optimizer()\n\u001b[0;32m--> 566\u001b[0m xopt, retvals, optim_settings \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mhessian\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mretall\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretall\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;66;03m# Restore cov_type, cov_kwds and use_t\u001b[39;00m\n\u001b[1;32m    576\u001b[0m optim_settings\u001b[38;5;241m.\u001b[39mupdate(kwds)\n",
            "File \u001b[0;32m~/Documents/TFG_ADE/code/TFG/lib/python3.9/site-packages/statsmodels/base/optimizer.py:243\u001b[0m, in \u001b[0;36mOptimizer._fit\u001b[0;34m(self, objective, gradient, start_params, fargs, kwargs, hessian, method, maxiter, full_output, disp, callback, retall)\u001b[0m\n\u001b[1;32m    240\u001b[0m     fit_funcs\u001b[38;5;241m.\u001b[39mupdate(extra_fit_funcs)\n\u001b[1;32m    242\u001b[0m func \u001b[38;5;241m=\u001b[39m fit_funcs[method]\n\u001b[0;32m--> 243\u001b[0m xopt, retvals \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mretall\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mhess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhessian\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m optim_settings \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m: method, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_params\u001b[39m\u001b[38;5;124m'\u001b[39m: start_params,\n\u001b[1;32m    249\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m'\u001b[39m: maxiter, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull_output\u001b[39m\u001b[38;5;124m'\u001b[39m: full_output,\n\u001b[1;32m    250\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m'\u001b[39m: disp, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfargs\u001b[39m\u001b[38;5;124m'\u001b[39m: fargs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m'\u001b[39m: callback,\n\u001b[1;32m    251\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretall\u001b[39m\u001b[38;5;124m'\u001b[39m: retall, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_fit_funcs\u001b[39m\u001b[38;5;124m\"\u001b[39m: extra_fit_funcs}\n\u001b[1;32m    252\u001b[0m optim_settings\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n",
            "File \u001b[0;32m~/Documents/TFG_ADE/code/TFG/lib/python3.9/site-packages/statsmodels/base/optimizer.py:660\u001b[0m, in \u001b[0;36m_fit_lbfgs\u001b[0;34m(f, score, start_params, fargs, kwargs, disp, maxiter, callback, retall, full_output, hess)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m approx_grad:\n\u001b[1;32m    658\u001b[0m     func \u001b[38;5;241m=\u001b[39m f\n\u001b[0;32m--> 660\u001b[0m retvals \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin_l_bfgs_b\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m                                 \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_output:\n\u001b[1;32m    666\u001b[0m     xopt, fopt, d \u001b[38;5;241m=\u001b[39m retvals\n",
            "File \u001b[0;32m~/Documents/TFG_ADE/code/TFG/lib/python3.9/site-packages/scipy/optimize/_lbfgsb_py.py:237\u001b[0m, in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    225\u001b[0m callback \u001b[38;5;241m=\u001b[39m _wrap_callback(callback)\n\u001b[1;32m    226\u001b[0m opts \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m'\u001b[39m: disp,\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miprint\u001b[39m\u001b[38;5;124m'\u001b[39m: iprint,\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxcor\u001b[39m\u001b[38;5;124m'\u001b[39m: m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m'\u001b[39m: callback,\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxls\u001b[39m\u001b[38;5;124m'\u001b[39m: maxls}\n\u001b[0;32m--> 237\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m d \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrad\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjac\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    240\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    241\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfuncalls\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnfev\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    242\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnit\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnit\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    243\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwarnflag\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m    244\u001b[0m f \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfun\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "File \u001b[0;32m~/Documents/TFG_ADE/code/TFG/lib/python3.9/site-packages/scipy/optimize/_lbfgsb_py.py:407\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    401\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 407\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    410\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "File \u001b[0;32m~/Documents/TFG_ADE/code/TFG/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:297\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
            "File \u001b[0;32m~/Documents/TFG_ADE/code/TFG/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:267\u001b[0m, in \u001b[0;36mScalarFunction._update_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_grad\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_updated:\n\u001b[0;32m--> 267\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_grad_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/TFG_ADE/code/TFG/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:181\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_grad\u001b[0;34m()\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg \u001b[38;5;241m=\u001b[39m \u001b[43mapprox_derivative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfinite_diff_options\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/TFG_ADE/code/TFG/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:519\u001b[0m, in \u001b[0;36mapprox_derivative\u001b[0;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[1;32m    516\u001b[0m     use_one_sided \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparsity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_dense_difference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m                             \u001b[49m\u001b[43muse_one_sided\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(sparsity) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sparsity) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
            "File \u001b[0;32m~/Documents/TFG_ADE/code/TFG/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:590\u001b[0m, in \u001b[0;36m_dense_difference\u001b[0;34m(fun, x0, f0, h, use_one_sided, method)\u001b[0m\n\u001b[1;32m    588\u001b[0m     x \u001b[38;5;241m=\u001b[39m x0 \u001b[38;5;241m+\u001b[39m h_vecs[i]\n\u001b[1;32m    589\u001b[0m     dx \u001b[38;5;241m=\u001b[39m x[i] \u001b[38;5;241m-\u001b[39m x0[i]  \u001b[38;5;66;03m# Recompute dx as exactly representable number.\u001b[39;00m\n\u001b[0;32m--> 590\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m f0\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3-point\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m use_one_sided[i]:\n\u001b[1;32m    592\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m x0 \u001b[38;5;241m+\u001b[39m h_vecs[i]\n",
            "File \u001b[0;32m~/Documents/TFG_ADE/code/TFG/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:470\u001b[0m, in \u001b[0;36mapprox_derivative.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39misdtype(x\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreal floating\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    468\u001b[0m     x \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(x, x0\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 470\u001b[0m f \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_1d(\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`fun` return value has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    473\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmore than 1 dimension.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/Documents/TFG_ADE/code/TFG/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:145\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
            "File \u001b[0;32m~/Documents/TFG_ADE/code/TFG/lib/python3.9/site-packages/statsmodels/base/model.py:534\u001b[0m, in \u001b[0;36mLikelihoodModel.fit.<locals>.f\u001b[0;34m(params, *args)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(params, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 534\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloglike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m nobs\n",
            "File \u001b[0;32m~/Documents/TFG_ADE/code/TFG/lib/python3.9/site-packages/statsmodels/tsa/statespace/mlemodel.py:940\u001b[0m, in \u001b[0;36mMLEModel.loglike\u001b[0;34m(self, params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m complex_step:\n\u001b[1;32m    938\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minversion_method\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m INVERT_UNIVARIATE \u001b[38;5;241m|\u001b[39m SOLVE_LU\n\u001b[0;32m--> 940\u001b[0m loglike \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloglike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomplex_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomplex_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;66;03m# Koopman, Shephard, and Doornik recommend maximizing the average\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;66;03m# likelihood to avoid scale issues, but the averaging is done\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;66;03m# automatically in the base model `fit` method\u001b[39;00m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loglike\n",
            "File \u001b[0;32m~/Documents/TFG_ADE/code/TFG/lib/python3.9/site-packages/statsmodels/tsa/statespace/kalman_filter.py:1001\u001b[0m, in \u001b[0;36mKalmanFilter.loglike\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;124;03mCalculate the loglikelihood associated with the statespace model.\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[38;5;124;03m    The joint loglikelihood.\u001b[39;00m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    999\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconserve_memory\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1000\u001b[0m                   MEMORY_CONSERVE \u001b[38;5;241m^\u001b[39m MEMORY_NO_LIKELIHOOD)\n\u001b[0;32m-> 1001\u001b[0m kfilter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1002\u001b[0m loglikelihood_burn \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloglikelihood_burn\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1003\u001b[0m                                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloglikelihood_burn)\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconserve_memory\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m&\u001b[39m MEMORY_NO_LIKELIHOOD):\n",
            "File \u001b[0;32m~/Documents/TFG_ADE/code/TFG/lib/python3.9/site-packages/statsmodels/tsa/statespace/kalman_filter.py:924\u001b[0m, in \u001b[0;36mKalmanFilter._filter\u001b[0;34m(self, filter_method, inversion_method, stability_method, conserve_memory, filter_timing, tolerance, loglikelihood_burn, complex_step)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_state(prefix\u001b[38;5;241m=\u001b[39mprefix, complex_step\u001b[38;5;241m=\u001b[39mcomplex_step)\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# Run the filter\u001b[39;00m\n\u001b[0;32m--> 924\u001b[0m \u001b[43mkfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m kfilter\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "autoarimax_model = auto_arima(\n",
        "    y=y_train_boxcox,\n",
        "    X=x_train_exogs,  \n",
        "    start_p=0,\n",
        "    d=0,  \n",
        "    start_q=0,\n",
        "    max_p=3,  \n",
        "    max_q=3,\n",
        "    start_P=0,\n",
        "    D=1, #TODO: probar a usar D=0\n",
        "    sart_Q=0,\n",
        "    max_P=2, \n",
        "    max_Q=2,\n",
        "    m=12,\n",
        "    seasonal=True,\n",
        "    trace=True,\n",
        "    error_action=\"warn\",\n",
        "    suppress_warnings=True,\n",
        "    stepwise=True,  \n",
        "    n_fits=50,  \n",
        "    information_criterion='aic', \n",
        ")\n",
        " \n",
        "print(autoarimax_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7f9baa1",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# --- Residuos (en escala Box-Cox) ---\n",
        "residuals = autoarimax_model.resid()\n",
        "print(\"\\n----------------- Residuals White Noise Test (Box-Cox) -----------------\")\n",
        "sa.residual_white_noise_test(residuals)\n",
        "print(\"-----------------------------------------------------------------------\")\n",
        "\n",
        "# Diagn√≥stico de residuos (Box-Cox)\n",
        "residuals_boxcox = autoarimax_model.arima_res_.resid\n",
        "fitted_values_boxcox = autoarimax_model.arima_res_.fittedvalues\n",
        "sa.analysis_residuals(residuals_boxcox, fitted_values_boxcox)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "313d7f3e",
      "metadata": {},
      "outputs": [],
      "source": [
        "autoarimax_model_v2 = auto_arima(\n",
        "    y=y_train_boxcox,\n",
        "    X=x_train_exogs,  \n",
        "    start_p=0,\n",
        "    d=0,  \n",
        "    start_q=0,\n",
        "    max_p=3,  \n",
        "    max_q=3,\n",
        "    start_P=0,\n",
        "    D=1, #TODO: probar a usar D=0\n",
        "    start_Q=0,\n",
        "    max_P=2, \n",
        "    max_Q=2,\n",
        "    m=12,\n",
        "    seasonal=True,\n",
        "    trace=True,\n",
        "    error_action=\"warn\",\n",
        "    suppress_warnings=True,\n",
        "    stepwise=True,  \n",
        "    n_fits=50,  \n",
        "    information_criterion='aic', \n",
        ")\n",
        " \n",
        "print(autoarimax_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80a4edd8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Residuos (en escala Box-Cox) ---\n",
        "residuals = autoarimax_model_v2.resid()\n",
        "print(\"\\n----------------- Residuals White Noise Test (Box-Cox) -----------------\")\n",
        "sa.residual_white_noise_test(residuals)\n",
        "print(\"-----------------------------------------------------------------------\")\n",
        "\n",
        "# Diagn√≥stico de residuos (Box-Cox)\n",
        "residuals_boxcox = autoarimax_model_v2.arima_res_.resid\n",
        "fitted_values_boxcox = autoarimax_model_v2.arima_res_.fittedvalues\n",
        "sa.analysis_residuals(residuals_boxcox, fitted_values_boxcox)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "TFG",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
